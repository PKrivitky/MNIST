# MNIST Classification Project

Этот проект – простой пример классификации изображений из датасета **MNIST**. Я считаю, что некрасиво оставлять такой популярный датасет без внимания, ведь он является настоящей базой для начинающих ML инженеров. Здесь я реализовал две модели: простую полносвязную нейронную сеть и сверточную нейронную сеть (LeNet). Также провёл эксперимент с различными функциями активации (ELU, ReLU, LeakyReLU) для оценки их влияния на качество обучения.

## О проекте

В рамках проекта использовались следующие подходы:
- **Полносвязная нейронная сеть** – базовая архитектура, позволяющая быстро и наглядно продемонстрировать процесс обучения на MNIST.
- **Функции активации** – протестированы ELU, ReLU и LeakyReLU. Это помогло понять, как выбор функции активации влияет на скорость сходимости и качество модели.
- **CNN LeNet** – классическая архитектура для задач компьютерного зрения, которая показала достойные результаты при работе с рукописными цифрами.

## Почему MNIST?
Датасет MNIST давно стал «Hello, world» в машинном обучении. Он прост в использовании, но при этом позволяет изучить основные принципы работы нейронных сетей, такие как обучение, тестирование, валидация и настройка гиперпараметров.

## Основные шаги проекта

1. **Загрузка и подготовка данных**
   - Импорт библиотеки `torchvision.datasets` для загрузки MNIST.
   - Нормализация изображений и разделение на тренировочную и тестовую выборки.

2. **Реализация моделей**
   - **Полносвязная сеть:** Состоит из нескольких слоёв, где после каждого слоя применяется выбранная функция активации.
   - **CNN (LeNet):** Использует сверточные и полносвязные слои для выделения признаков и классификации изображений.

3. **Эксперименты с функциями активации**
   - Провёл сравнение между ELU, ReLU и LeakyReLU, чтобы выявить оптимальный вариант для данной задачи.


## Вывод

Проект показал, что даже простые модели могут эффективно решать задачу классификации на датасете MNIST.  
- Полносвязная сеть, несмотря на свою простоту, дает неплохие результаты при правильном выборе функций активации.  
- Архитектура LeNet демонстрирует высокую точность и стабильность благодаря специально разработанным слоям для извлечения признаков.  

Эти эксперименты дают хорошую базу для понимания основ работы нейронных сетей и могут служить отправной точкой для дальнейших исследований и разработки более сложных моделей.


